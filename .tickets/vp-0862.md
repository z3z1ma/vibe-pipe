---
"id": "vp-0862"
"status": "open"
"deps": []
"links": []
"created": "2026-01-28T01:26:11Z"
"type": "feature"
"priority": 1
"assignee": "z3z1ma"
"tags":
- "phase2"
- "integration"
- "database"
"external": {}
---
# Database Connectors

Build database connectors for common databases (PostgreSQL, MySQL, Snowflake, BigQuery) to enable VibePiper to interact with real data sources.

## Tasks
1. Create DatabaseConnector protocol with connect(), query(), disconnect() methods
2. Implement PostgreSQL connector (via psycopg2 or asyncpg)
3. Implement MySQL connector (via mysql-connector-python or aiomysql)
4. Implement Snowflake connector (via snowflake-connector-python)
5. Implement BigQuery connector (via google-cloud-bigquery)
6. Add connection pooling for all connectors
7. Add query builder helpers for common operations
8. Implement type-safe result mapping to schemas
9. Create integration tests with Docker Compose

## Example Usage
```python
from vibe_piper import asset
from vibe_piper.connectors import PostgreSQLConnector

connector = PostgreSQLConnector(
    host="localhost",
    port=5432,
    database="mydb",
    user="user",
    password="password",
    pool_size=10
)

@asset(io_manager="postgresql", connector="my_connector")
def customers(connector: PostgreSQLConnector):
    return connector.query("SELECT * FROM customers WHERE active = true")
```

## Dependencies
- vp-101 (IO Manager abstraction)

## Technical Notes
- Use SQLAlchemy for database abstraction where possible
- Support both sync and async operations
- Implement proper connection lifecycle management
- Handle connection errors gracefully
- Support parameterized queries to prevent SQL injection

## Acceptance Criteria

4 database connectors working (PostgreSQL, MySQL, Snowflake, BigQuery)
Connection pooling configured and tested
Query builder for common operations (SELECT, INSERT, UPDATE)
Type-safe result mapping to VibePiper schemas
Integration tests with real databases (via Docker)
Documentation for each connector
Test coverage > 85%
